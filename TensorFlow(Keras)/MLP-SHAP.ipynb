{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ffb79d87fcd4372b8c2a87767990f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07c669af8c31412e89f6905b543fa8dd",
              "IPY_MODEL_4c0271c1262e406c951581bb2da3d42a",
              "IPY_MODEL_b2a99be3723e4ed4bb62f033e9f53900"
            ],
            "layout": "IPY_MODEL_d143c3c7fb73446b8eee1d7ae9b98300"
          }
        },
        "07c669af8c31412e89f6905b543fa8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ff77a55ac0404e8bef75503903d7a9",
            "placeholder": "​",
            "style": "IPY_MODEL_f674ecf8be48450e836d74fbc1e8b4b7",
            "value": "100%"
          }
        },
        "4c0271c1262e406c951581bb2da3d42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bca623465c1486ab4b7d78341dfbae4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12bfd5ee604f426d89bd9a275b6e8324",
            "value": 1
          }
        },
        "b2a99be3723e4ed4bb62f033e9f53900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c00986cf8b486c84c2c99446fcd23d",
            "placeholder": "​",
            "style": "IPY_MODEL_8e70b03a13d9476bb0404224b421c9cd",
            "value": " 1/1 [00:05&lt;00:00,  5.80s/it]"
          }
        },
        "d143c3c7fb73446b8eee1d7ae9b98300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ff77a55ac0404e8bef75503903d7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f674ecf8be48450e836d74fbc1e8b4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bca623465c1486ab4b7d78341dfbae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bfd5ee604f426d89bd9a275b6e8324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54c00986cf8b486c84c2c99446fcd23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e70b03a13d9476bb0404224b421c9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNxu8xIee_Wn",
        "outputId": "a076bf9e-d18b-497c-8c22-a54e19ab8416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-93a8df37e760>:5: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-whitegrid')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split # regression에서는 사용 편함.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, Model, layers\n",
        "\n",
        "SEED = 511\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_data = 3000\n",
        "x1 = np.random.rand(num_data)\n",
        "x2 = np.random.rand(num_data)\n",
        "x3 = np.random.rand(num_data)\n",
        "x4 = np.random.rand(num_data)\n",
        "\n",
        "X = np.array([x1, x2, x3, x4]).T\n",
        "y = x1 + x2**2 + 10*x3 + np.log(x4)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKNNueGPuMhB",
        "outputId": "a0fa2dac-581a-474e-9939-25dba031f20d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3000, 4)\n",
            "(3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xscaler = MinMaxScaler()\n",
        "yscaler = MinMaxScaler()\n",
        "\n",
        "xscaler.fit(X)\n",
        "scaled_x = xscaler.transform(X)\n",
        "\n",
        "yscaler.fit(y)\n",
        "scaled_y = yscaler.transform(y)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "xtrain = tf.constant(xtrain, dtype=tf.float32)\n",
        "xtest = tf.constant(xtest, dtype=tf.float32)\n",
        "ytrain = tf.constant(ytrain, dtype=tf.float32)\n",
        "ytest = tf.constant(ytest, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "sW2l99fejkhN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(xtrain), seed=SEED).batch(batch_size=64)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((xtest, ytest))\n",
        "test_dataset = test_dataset.shuffle(buffer_size=len(ytrain), seed=SEED).batch(batch_size=64)"
      ],
      "metadata": {
        "id": "wHOcR-ILoeFo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN(Model):\n",
        "    def __init__(self,):\n",
        "        super(ANN, self).__init__()\n",
        "        self.fc1 = layers.Dense(units=64, input_dim=xtrain.shape[1], activation=tf.nn.gelu)\n",
        "        self.dropout1 = layers.Dropout(0.5)\n",
        "        self.fc2 = layers.Dense(units=64, activation=tf.nn.gelu)\n",
        "        self.dropout2 = layers.Dropout(0.5)\n",
        "        self.out = layers.Dense(units=ytrain.shape[1], activation=None)\n",
        "\n",
        "    def call(self, x, is_training=False):\n",
        "        x = self.fc1(x)\n",
        "        if is_training:\n",
        "            x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        if is_training:\n",
        "            x = self.dropout2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lCApkHc4o8TX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.MeanSquaredError()\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model = ANN()"
      ],
      "metadata": {
        "id": "eIMF_94_qno8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losslist = []\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "    for epoch in range(1, 800+1):\n",
        "        total_loss = 0.0\n",
        "        num_batches = int(0)\n",
        "\n",
        "        for x, y_true in train_dataset:\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = model(x, is_training=True)\n",
        "                loss = loss_fn(y_true, y_pred)\n",
        "                total_loss += loss\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "            num_batches += 1\n",
        "\n",
        "        losslist.append( total_loss/num_batches )\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            print(f\"[Epoch]: {epoch}/800,  [Loss]: {np.round(total_loss / num_batches, 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzDREBnYqiCk",
        "outputId": "8d15b6ca-2744-4c62-820a-e99f53a654e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7e080ccdecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7e080ccdecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch]: 2/800,  [Loss]: 7.747000217437744\n",
            "[Epoch]: 4/800,  [Loss]: 2.385999917984009\n",
            "[Epoch]: 6/800,  [Loss]: 0.5809999704360962\n",
            "[Epoch]: 8/800,  [Loss]: 0.41200000047683716\n",
            "[Epoch]: 10/800,  [Loss]: 0.38199999928474426\n",
            "[Epoch]: 12/800,  [Loss]: 0.367000013589859\n",
            "[Epoch]: 14/800,  [Loss]: 0.35600000619888306\n",
            "[Epoch]: 16/800,  [Loss]: 0.34299999475479126\n",
            "[Epoch]: 18/800,  [Loss]: 0.33500000834465027\n",
            "[Epoch]: 20/800,  [Loss]: 0.3310000002384186\n",
            "[Epoch]: 22/800,  [Loss]: 0.3149999976158142\n",
            "[Epoch]: 24/800,  [Loss]: 0.2980000078678131\n",
            "[Epoch]: 26/800,  [Loss]: 0.2919999957084656\n",
            "[Epoch]: 28/800,  [Loss]: 0.2770000100135803\n",
            "[Epoch]: 30/800,  [Loss]: 0.2590000033378601\n",
            "[Epoch]: 32/800,  [Loss]: 0.2460000067949295\n",
            "[Epoch]: 34/800,  [Loss]: 0.22300000488758087\n",
            "[Epoch]: 36/800,  [Loss]: 0.20600000023841858\n",
            "[Epoch]: 38/800,  [Loss]: 0.18199999630451202\n",
            "[Epoch]: 40/800,  [Loss]: 0.15600000321865082\n",
            "[Epoch]: 42/800,  [Loss]: 0.13699999451637268\n",
            "[Epoch]: 44/800,  [Loss]: 0.12099999934434891\n",
            "[Epoch]: 46/800,  [Loss]: 0.10999999940395355\n",
            "[Epoch]: 48/800,  [Loss]: 0.1080000028014183\n",
            "[Epoch]: 50/800,  [Loss]: 0.09700000286102295\n",
            "[Epoch]: 52/800,  [Loss]: 0.09200000017881393\n",
            "[Epoch]: 54/800,  [Loss]: 0.08699999749660492\n",
            "[Epoch]: 56/800,  [Loss]: 0.08100000023841858\n",
            "[Epoch]: 58/800,  [Loss]: 0.07999999821186066\n",
            "[Epoch]: 60/800,  [Loss]: 0.07100000232458115\n",
            "[Epoch]: 62/800,  [Loss]: 0.06599999964237213\n",
            "[Epoch]: 64/800,  [Loss]: 0.06300000101327896\n",
            "[Epoch]: 66/800,  [Loss]: 0.05999999865889549\n",
            "[Epoch]: 68/800,  [Loss]: 0.054999999701976776\n",
            "[Epoch]: 70/800,  [Loss]: 0.05000000074505806\n",
            "[Epoch]: 72/800,  [Loss]: 0.04899999871850014\n",
            "[Epoch]: 74/800,  [Loss]: 0.04600000008940697\n",
            "[Epoch]: 76/800,  [Loss]: 0.04399999976158142\n",
            "[Epoch]: 78/800,  [Loss]: 0.04100000113248825\n",
            "[Epoch]: 80/800,  [Loss]: 0.03799999877810478\n",
            "[Epoch]: 82/800,  [Loss]: 0.03999999910593033\n",
            "[Epoch]: 84/800,  [Loss]: 0.035999998450279236\n",
            "[Epoch]: 86/800,  [Loss]: 0.03500000014901161\n",
            "[Epoch]: 88/800,  [Loss]: 0.04100000113248825\n",
            "[Epoch]: 90/800,  [Loss]: 0.03200000151991844\n",
            "[Epoch]: 92/800,  [Loss]: 0.03099999949336052\n",
            "[Epoch]: 94/800,  [Loss]: 0.03099999949336052\n",
            "[Epoch]: 96/800,  [Loss]: 0.028999999165534973\n",
            "[Epoch]: 98/800,  [Loss]: 0.03099999949336052\n",
            "[Epoch]: 100/800,  [Loss]: 0.028999999165534973\n",
            "[Epoch]: 102/800,  [Loss]: 0.027000000700354576\n",
            "[Epoch]: 104/800,  [Loss]: 0.02800000086426735\n",
            "[Epoch]: 106/800,  [Loss]: 0.027000000700354576\n",
            "[Epoch]: 108/800,  [Loss]: 0.026000000536441803\n",
            "[Epoch]: 110/800,  [Loss]: 0.02500000037252903\n",
            "[Epoch]: 112/800,  [Loss]: 0.02500000037252903\n",
            "[Epoch]: 114/800,  [Loss]: 0.024000000208616257\n",
            "[Epoch]: 116/800,  [Loss]: 0.027000000700354576\n",
            "[Epoch]: 118/800,  [Loss]: 0.024000000208616257\n",
            "[Epoch]: 120/800,  [Loss]: 0.026000000536441803\n",
            "[Epoch]: 122/800,  [Loss]: 0.024000000208616257\n",
            "[Epoch]: 124/800,  [Loss]: 0.02500000037252903\n",
            "[Epoch]: 126/800,  [Loss]: 0.020999999716877937\n",
            "[Epoch]: 128/800,  [Loss]: 0.02199999988079071\n",
            "[Epoch]: 130/800,  [Loss]: 0.019999999552965164\n",
            "[Epoch]: 132/800,  [Loss]: 0.020999999716877937\n",
            "[Epoch]: 134/800,  [Loss]: 0.01899999938905239\n",
            "[Epoch]: 136/800,  [Loss]: 0.019999999552965164\n",
            "[Epoch]: 138/800,  [Loss]: 0.017999999225139618\n",
            "[Epoch]: 140/800,  [Loss]: 0.017999999225139618\n",
            "[Epoch]: 142/800,  [Loss]: 0.020999999716877937\n",
            "[Epoch]: 144/800,  [Loss]: 0.01600000075995922\n",
            "[Epoch]: 146/800,  [Loss]: 0.017000000923871994\n",
            "[Epoch]: 148/800,  [Loss]: 0.017000000923871994\n",
            "[Epoch]: 150/800,  [Loss]: 0.017999999225139618\n",
            "[Epoch]: 152/800,  [Loss]: 0.017999999225139618\n",
            "[Epoch]: 154/800,  [Loss]: 0.019999999552965164\n",
            "[Epoch]: 156/800,  [Loss]: 0.020999999716877937\n",
            "[Epoch]: 158/800,  [Loss]: 0.01600000075995922\n",
            "[Epoch]: 160/800,  [Loss]: 0.017000000923871994\n",
            "[Epoch]: 162/800,  [Loss]: 0.014999999664723873\n",
            "[Epoch]: 164/800,  [Loss]: 0.014000000432133675\n",
            "[Epoch]: 166/800,  [Loss]: 0.014000000432133675\n",
            "[Epoch]: 168/800,  [Loss]: 0.01600000075995922\n",
            "[Epoch]: 170/800,  [Loss]: 0.017000000923871994\n",
            "[Epoch]: 172/800,  [Loss]: 0.014999999664723873\n",
            "[Epoch]: 174/800,  [Loss]: 0.014000000432133675\n",
            "[Epoch]: 176/800,  [Loss]: 0.014999999664723873\n",
            "[Epoch]: 178/800,  [Loss]: 0.017000000923871994\n",
            "[Epoch]: 180/800,  [Loss]: 0.013000000268220901\n",
            "[Epoch]: 182/800,  [Loss]: 0.01600000075995922\n",
            "[Epoch]: 184/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 186/800,  [Loss]: 0.014000000432133675\n",
            "[Epoch]: 188/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 190/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 192/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 194/800,  [Loss]: 0.013000000268220901\n",
            "[Epoch]: 196/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 198/800,  [Loss]: 0.013000000268220901\n",
            "[Epoch]: 200/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 202/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 204/800,  [Loss]: 0.009999999776482582\n",
            "[Epoch]: 206/800,  [Loss]: 0.009999999776482582\n",
            "[Epoch]: 208/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 210/800,  [Loss]: 0.009999999776482582\n",
            "[Epoch]: 212/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 214/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 216/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 218/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 220/800,  [Loss]: 0.009999999776482582\n",
            "[Epoch]: 222/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 224/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 226/800,  [Loss]: 0.010999999940395355\n",
            "[Epoch]: 228/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 230/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 232/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 234/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 236/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 238/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 240/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 242/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 244/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 246/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 248/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 250/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 252/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 254/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 256/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 258/800,  [Loss]: 0.012000000104308128\n",
            "[Epoch]: 260/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 262/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 264/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 266/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 268/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 270/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 272/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 274/800,  [Loss]: 0.008999999612569809\n",
            "[Epoch]: 276/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 278/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 280/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 282/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 284/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 286/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 288/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 290/800,  [Loss]: 0.01899999938905239\n",
            "[Epoch]: 292/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 294/800,  [Loss]: 0.009999999776482582\n",
            "[Epoch]: 296/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 298/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 300/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 302/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 304/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 306/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 308/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 310/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 312/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 314/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 316/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 318/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 320/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 322/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 324/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 326/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 328/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 330/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 332/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 334/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 336/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 338/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 340/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 342/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 344/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 346/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 348/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 350/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 352/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 354/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 356/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 358/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 360/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 362/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 364/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 366/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 368/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 370/800,  [Loss]: 0.00800000037997961\n",
            "[Epoch]: 372/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 374/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 376/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 378/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 380/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 382/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 384/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 386/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 388/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 390/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 392/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 394/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 396/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 398/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 400/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 402/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 404/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 406/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 408/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 410/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 412/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 414/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 416/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 418/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 420/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 422/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 424/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 426/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 428/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 430/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 432/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 434/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 436/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 438/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 440/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 442/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 444/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 446/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 448/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 450/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 452/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 454/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 456/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 458/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 460/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 462/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 464/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 466/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 468/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 470/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 472/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 474/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 476/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 478/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 480/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 482/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 484/800,  [Loss]: 0.006000000052154064\n",
            "[Epoch]: 486/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 488/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 490/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 492/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 494/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 496/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 498/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 500/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 502/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 504/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 506/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 508/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 510/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 512/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 514/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 516/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 518/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 520/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 522/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 524/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 526/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 528/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 530/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 532/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 534/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 536/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 538/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 540/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 542/800,  [Loss]: 0.004999999888241291\n",
            "[Epoch]: 544/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 546/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 548/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 550/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 552/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 554/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 556/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 558/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 560/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 562/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 564/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 566/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 568/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 570/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 572/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 574/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 576/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 578/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 580/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 582/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 584/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 586/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 588/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 590/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 592/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 594/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 596/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 598/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 600/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 602/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 604/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 606/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 608/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 610/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 612/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 614/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 616/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 618/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 620/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 622/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 624/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 626/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 628/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 630/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 632/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 634/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 636/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 638/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 640/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 642/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 644/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 646/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 648/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 650/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 652/800,  [Loss]: 0.007000000216066837\n",
            "[Epoch]: 654/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 656/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 658/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 660/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 662/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 664/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 666/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 668/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 670/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 672/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 674/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 676/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 678/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 680/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 682/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 684/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 686/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 688/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 690/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 692/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 694/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 696/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 698/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 700/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 702/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 704/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 706/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 708/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 710/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 712/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 714/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 716/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 718/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 720/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 722/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 724/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 726/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 728/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 730/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 732/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 734/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 736/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 738/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 740/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 742/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 744/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 746/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 748/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 750/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 752/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 754/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 756/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 758/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 760/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 762/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 764/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 766/800,  [Loss]: 0.004000000189989805\n",
            "[Epoch]: 768/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 770/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 772/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 774/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 776/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 778/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 780/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 782/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 784/800,  [Loss]: 0.003000000026077032\n",
            "[Epoch]: 786/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 788/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 790/800,  [Loss]: 0.0020000000949949026\n",
            "[Epoch]: 792/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 794/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 796/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 798/800,  [Loss]: 0.0010000000474974513\n",
            "[Epoch]: 800/800,  [Loss]: 0.0010000000474974513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss = 0.0\n",
        "num_batches = 0\n",
        "predlist= []\n",
        "\n",
        "for x, y_true in test_dataset:\n",
        "    y_pred = model(x, is_training=False)  # 평가 모드에서는 is_training=False\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "    total_loss += loss\n",
        "    num_batches += 1\n",
        "    predlist += y_pred.numpy().ravel().tolist()\n",
        "\n",
        "avg_loss = np.round(total_loss / num_batches, 4)\n",
        "print(f'[Avg_Loss]: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1mzpRjtsSAK",
        "outputId": "ec04e063-e027-4b1e-9d08-1deac887b935"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Avg_Loss]: 0.023600000888109207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRlL8vSVfGH1",
        "outputId": "2877ab77-9713-45cb-ab3e-50c8f5ee5e03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.KernelExplainer(model.predict, xtrain.numpy())\n",
        "shap_values = explainer.shap_values(xtest.numpy()[0, :].reshape(1, -1))\n",
        "print(shap_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "9ffb79d87fcd4372b8c2a87767990f0e",
            "07c669af8c31412e89f6905b543fa8dd",
            "4c0271c1262e406c951581bb2da3d42a",
            "b2a99be3723e4ed4bb62f033e9f53900",
            "d143c3c7fb73446b8eee1d7ae9b98300",
            "c2ff77a55ac0404e8bef75503903d7a9",
            "f674ecf8be48450e836d74fbc1e8b4b7",
            "7bca623465c1486ab4b7d78341dfbae4",
            "12bfd5ee604f426d89bd9a275b6e8324",
            "54c00986cf8b486c84c2c99446fcd23d",
            "8e70b03a13d9476bb0404224b421c9cd"
          ]
        },
        "id": "zT7TKmI3z0hi",
        "outputId": "1bbc9f9e-29b7-4a95-c66f-7e8e6a38c558"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:shap:Using 2400 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ffb79d87fcd4372b8c2a87767990f0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "1050/1050 [==============================] - 2s 2ms/step\n",
            "[array([[ 0.15208316,  0.23087082, -4.31642542,  0.26546765]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kane = tf.constant( xtest[0, :].numpy().reshape(1, -1) )\n",
        "model(kane, is_training=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBH870fM1Dg6",
        "outputId": "b6801c83-6525-458f-dea3-9410bb8c6f12"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.0373502]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, kane, feature_names=['x1', 'x2', 'x3', 'x4'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "n5rLGJCrfGBO",
        "outputId": "ece41d5f-3b9f-4e79-8f31-02f224c69ab8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x310 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEsCAYAAABewCVFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8cElEQVR4nO3deXgNd///8VckCEJQS9xKaXsnNMSW2pVwU6VBufWuJajG0haldmpLLdVaQuxpkKguN6HVUvtSNLThphRtKaFqqdr35JjfH77n/JychJNM0nPU83FdrkvmfGbmPZNP5pzXmc/MeBiGYQgAAAAATMjh6gIAAAAAPPwIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADT3CZYJCQk6NatW64uA9CdO3f0ww8/6M6dO64uBZBEn4T7oU/CndAf3YfbBItcuXLJMAxXlwHIMAwlJyfTH+E26JNwN/RJuBP6o/twm2ABAAAA4OFFsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmOZhGIbh6iIkyWNSiqtLAAAAAFzOGODl6hIyhTMWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMy/LH+n3zzTeKi4vTkSNHlJycLH9/f3Xs2FENGzbM6lUBAAAAcBNZesZi1apVevvtt1WiRAlNmDBBEyZMkJeXlwYNGqS1a9dm5aoAAAAAuBEPwzCMrFpYaGio/Pz8FB0dbZt29epVNW/eXOXLl9ecOXPSL2RSSlaVAQAAADy0jAFZPqjoL+H0GYvNmzcrODhYS5YssZseGxur4OBgbd68WWFhYerZs6fd6z4+PipTpoxOnTqVNRUDAAAAcDtOx6EGDRqoadOmmjVrlho1aqTChQvrzJkz+vDDD9WqVSs1aNAgzflSUlJ0+vRpBQQEZFXNAAAAANxMhq6xGDhwoHLlyqXIyEhJ0uTJk1WgQAH17dvXoa3FYlFSUpKGDh2q27dvO5zJAAAAAPD3kaEBXL6+vho6dKgGDBggPz8/bdy4UTNmzJCPj49duy+//FJjxoyRJPn7+2vWrFkqX7581lUNAAAA/E1ZLBZXl2DH09PTqXaZunh76NChWrdunUJDQzVq1CiH1y9duqRTp07p3LlzWrVqlTZv3qyhQ4cqNDQ0/UK4eBsAAABQYsheV5dgp1q1ak61y/Al5ykpKUpKSpKHh4eOHDkii8XikGJ8fX3l6+srSapbt65GjBih9957T/Xr11eBAgUyukoAAADgkVG5cmVXl5ApGX6OxcKFC5WUlKQpU6bol19+UWxsrCTp3Llz+vzzz/Xrr786zBMQEKBbt27p+PHj5isGAAAA/sY8PT3d6p+zMhQsDh8+rJiYGIWHh6tevXrq1KmToqOjdeTIEd2+fVtjx47VggULHObbt2+fJMnPzy8jqwMAAADwkHB6KJTFYlFERIRKly6tsLAwSVLXrl21du1ajRkzRgsWLFCzZs20atUq+fj4qH79+pKkTZs2acOGDQoNDVWRIkWyZysAAAAAuJTTwWLRokU6ePCgYmJi5OV1d7bcuXNryJAhevPNNxUbG6uRI0fK399fX331lVasWKGcOXOqZMmS6t27tzp06JBtGwEAAADAtTJ1V6jswF2hAAAAAMkYkOH7K7mFDF+8DQAAAACpESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAprnNk7d37dqlwMBAeXt7u7oUPOIsFov27NmjypUry9PT09XlAPRJuB36JNwJ/dF9cMYCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmebm6AKvgTZWkTZKU4upSnGIMcJtdBwAAALgcZywAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJiWrcFi9+7devbZZ9W9e/fsXA0AAAAAF8u2YHH79m2NGzdOhmFk1yoAAAAAuIlsCxYxMTG6cuWKnnnmmexaBQAAAAA34XSw2Lx5s4KDg7VkyRK76bGxsQoODlZCQoJt2uHDhxUbG6tevXrJ29s766oFAAAA4JacDhYNGjRQ06ZNNWvWLJ0/f16SdObMGX344Ydq1aqVatWqJUm6c+eOxo8fr6CgILVo0SJ7qgYAAADgVrwy0njgwIH6/vvvFRkZqYiICE2ePFkFChRQ3759bW2WLl2qQ4cO6eOPP87qWt2KxWJxdQnIJtbfLb9juAv6JNwNfRLuhP6Y/Tw9PZ1ql6Fg4evrq6FDh2rAgAHy8/PTxo0bNWPGDPn4+Ei6ewZj5syZ6ty5s8qUKZPhoh8me/bscXUJyGb79u1zdQmAHfok3A19Eu6E/ph9qlWr5lS7DAUL6e6QqMaNG2v+/PkKDQ1VzZo1ba9NnDhRRYoU0auvvprRxT50Kleu7OoSkE0sFov27dunihUrOp3QgexEn4S7oU/CndAf3UeGg0VKSoqSkpLk4eGhI0eOyGKxyNPTUxs2bNDWrVs1depUpaSkKCUlRdLday4k6fr168qZM6dy5syZtVvgInTcvz9PT09+z3Ar9Em4G/ok3An90fUyfLvZhQsXKikpSVOmTNEvv/yi2NhYSdLWrVtlGIb69u2r5557zvZvz5492rNnj5577jnNnz8/yzcAAAAAgOtl6IzF4cOHFRMTo+7du6tevXrq1KmToqOjVb9+fXXt2lWtWrVymOf999+XJA0aNEh+fn5ZUjQAAAAA9+J0sLBYLIqIiFDp0qUVFhYmSeratavWrl2rMWPGaMGCBSpdurTDfNYLu7kmAQAAAPj7cnoo1KJFi3Tw4EENHz5cXl5380ju3Lk1ZMgQHThwwDYkCgAAAMCjx+kzFl26dFGXLl0cpteoUUOJiYnpzjdv3rxMFQYAAADg4ZHhi7cBAAAAIDWCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0p5+8nd0SQ/YqMDBQ3t7eri4FAAAAQAZxxgIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaV6uLsAqeFMlaZMkpbi6FDvGALfZRQAAAIDb4owFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATPPK6gXu3LlT8+bN06FDh5Q7d249+eST6tKli+rWrZvVqwIAAADgJrL0jMU333yjN998U/ny5dMHH3ygiIgI5cqVS3379tX69euzclUAAAAA3EiWnrGYOXOmSpcurSlTpsjL6+6ig4OD1bx5c3366af617/+lZWrAwAAAOAmnD5jsXnzZgUHB2vJkiV202NjYxUcHKyEhASFh4dr2LBhtlAhSd7e3ipVqpTOnDmTdVUDAAAAcCtOn7Fo0KCBmjZtqlmzZqlRo0YqXLiwzpw5ow8//FCtWrVSrVq10pwvJSVFJ06cUEBAQJYVDQAAAMC9ZGgo1MCBA/X9998rMjJSERERmjx5sgoUKKC+ffumO8/cuXN16dIl/fvf/zZbq0tYLBZXl4C/mPV3zu8e7oI+CXdDn4Q7oT9mP09PT6faZShY+Pr6aujQoRowYID8/Py0ceNGzZgxQz4+Pmm2j4+P18KFCxUaGqqGDRtmZFVuY8+ePa4uAS6yb98+V5cA2KFPwt3QJ+FO6I/Zp1q1ak61y/DF2w0aNFDjxo01f/58hYaGqmbNmmm2i46O1ty5c/XCCy9o+PDhGV2N26hcubKrS8BfzGKxaN++fapYsaLTCR3ITvRJuBv6JNwJ/dF9ZDhYpKSkKCkpSR4eHjpy5IgsFovDL3HChAmKj49Xp06d1Lt3b3l4eGRZwX81Ouijy9PTk98/3Ap9Eu6GPgl3Qn90vQw/x2LhwoVKSkrSlClT9Msvvyg2Ntbu9ZkzZ2rZsmUaMGCA+vTp81CHCgAAAADOyVCwOHz4sGJiYhQeHq569eqpU6dOio6O1pEjRyTdvSXtggUL1KtXL73yyivZUjAAAAAA9+N0sLBYLIqIiFDp0qUVFhYmSeratav8/Pw0ZswY3b59W1OnTlXJkiUVHBysAwcOOPxLTk7Otg0BAAAA4DpOX2OxaNEiHTx4UDExMbYH4OXOnVtDhgzRm2++qY8++kgnT56UJHXu3DnNZaxYsUL/+Mc/sqBsAAAAAO7E6WDRpUsXdenSxWF6jRo1lJiYKOnuGQwAAAAAj54MX7wNAAAAAKkRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmOf3k7eyWGLJXgYGB8vb2dnUpAAAAADKIMxYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATPNydQFWwZsqSZskKSXb1mEMcJvNBQAAAP5WOGMBAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMC0bAkWP//8s9q0aaPg4GAdO3YsO1YBAAAAwI1kebBYsmSJunTpomvXrmX1ogEAAAC4qSwNFrt27VJkZKQGDx6sl156KSsXDQAAAMCNOR0sNm/erODgYC1ZssRuemxsrIKDg5WQkCBfX1/FxMSoZcuWWV4oAAAAAPfl5WzDBg0aqGnTppo1a5YaNWqkwoUL68yZM/rwww/VqlUr1apVKzvrBAAAAODGMjQUauDAgcqVK5ciIyMlSZMnT1aBAgXUt2/fbCgNAAAAwMPC6TMWkuTr66uhQ4dqwIAB8vPz08aNGzVjxgz5+PhkV31ZymKxuLoEPASs/YT+AndBn4S7oU/CndAfs5+np6dT7TIULKS7Q6IaN26s+fPnKzQ0VDVr1sxwca6yZ88eV5eAh8i+fftcXQJghz4Jd0OfhDuhP2afatWqOdUuw8EiJSVFSUlJ8vDw0JEjR2SxWJxOMa5WuXJlV5eAh4DFYtG+fftUsWLFh6Zv4++NPgl3Q5+EO6E/uo8MB4uFCxcqKSlJU6ZM0aBBgxQbG6uuXbtmR21Zjs6GjPD09KTPwK3QJ+Fu6JNwJ/RH18vQxduHDx9WTEyMwsPDVa9ePXXq1EnR0dE6cuRIdtUHAAAA4CHgdLCwWCyKiIhQ6dKlFRYWJknq2rWr/Pz8NGbMGFksFv3+++86cOCADhw4oHPnzkmSjhw5YpuWnJycPVsBAAAAwKWcHgq1aNEiHTx4UDExMfLyujtb7ty5NWTIEL355puKjY3V8ePH9dVXX9nNN3jwYNv/V6xYoX/84x9ZVDoAAAAAd+F0sOjSpYu6dOniML1GjRpKTEy0/Tx69OisqAsAAADAQyRD11gAAAAAQFoIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATPNydQFWiSF7FRgYKG9vb1eXAgAAACCD3CZYAAAA4OHnMSnFBWutJG0yJN1dtzHA3Efcbdu26aOPPtLevXt15coVFSlSRJUqVVJYWJiCg4Nt7Ro2bKhKlSpp6tSpptaXFRITEzV16lTt379fOXPmVN26dTV06FAVL178L6uBoVAAAADA/4mMjFT37t1VqlQpzZ07V6tXr9a4ceN0/fp1hYWF6bPPPnN1iQ5+/fVXvfbaaypVqpSWL1+uuXPn6vfff1d4eLiSk5P/sjo4YwEAAABI2rJli2bPnq2RI0eqQ4cOtumPP/64ateurbfeekuTJk1S06ZN5evr68JK7UVHR6tQoUIaO3asvLzufrx/77339MILL2jNmjV68cUX/5I6OGMBAAAASJo/f77KlCmj9u3bO7zm4eGhiIgIbdiwId1QcfToUfXu3VvVq1dXhQoV1LhxY82ePVt37tyxtTl06JC6deummjVrKigoSM2aNdOiRYtsr1+6dEnDhw9XvXr1VKFCBdWvX19jx47VzZs3061727Ztqlu3ri1USNKTTz6pxx9/XN98801mdkWmcMYCAAAAj7yUlBTt3r1b7dq1k4eHR5ptChYsmO78hmGoe/fu8vX11cKFC+Xr66v//e9/GjJkiHx8fBQWFiZJ6tmzp6pUqaJFixYpT548+vbbbxUREaHHHntMzZo109ixY3Xo0CFNnz5dfn5++uWXXzRy5EglJydrzJgxDuu9du2azp49q9KlSzu89sQTT+jXX3/N3A7JBIIFAAAAHnkXLlzQ7du3VbJkyUwvY/78+cqTJ4+KFCkiSSpZsqTi4uK0detWhYWF6c8//9SpU6c0aNAg/fOf/5Qkvfzyy6pQoYKKFi0qSfrxxx/17LPPqkqVKpKkEiVKKC4uzu6sx72uXr0qScqXL5/Daz4+Pjp58mSmtyejCBYAAAB45FnPUhiGken5L1++rClTpmjv3r26ePGiDMPQzZs3VbFiRUlS4cKFVaVKFY0ePVqHDh1S3bp1VaVKFT3zzDO25TRq1Egffvihbt++rUaNGqlGjRppno1wRwQLAAAAPPIKFSqkPHnyKCkpKVPznzp1Sh07dtQTTzyhkSNHqlSpUvLy8tKAAQNsbTw8PBQTE6O4uDh9/fXXmjt3rvLnz6+2bduqX79+ypUrl95++2099dRTio+PV9++fSVJISEheuedd9K8dWz+/Pkl/f8zF/e6cuXKX3qRORdvAwAA4JHn6empZ599Vhs3blRKStrP4rh06ZL++9//pvn6+vXrdf36dU2ZMkUNGjTQU089pSeeeEKXL1+2a5cvXz69/vrrWrFihbZu3arXX39dixcv1uzZsyXdDR+tWrXSokWLtHPnTr3//vvav3+/3n777TRryps3r0qUKJFmIDp27JieeuqpjO6KTCNYAAAAAJK6du2q06dPa9asWQ6vGYahiIgITZgwQX/88YfD69bnRRQuXNg2bffu3Tp27JhteNWZM2e0atUq2+vFihXTa6+9pjp16ujgwYO6ceOGVq5caQsj+fLlU7NmzdS5c2cdPHgw3brr16+vrVu32j2z4sCBA/r999/VsGHDDO6FzCNYAAAAAJJq1aql3r17a+bMmRo8eLB2796tkydPaufOnerevbvWrVunDz74QCVKlHCYt3LlypKkuXPn6rffftP69esVERGhkJAQnThxQkePHtXly5fVv39/TZ48WYcPH9apU6e0fv167d69W9WrV5eXl5fef/99DRo0SD/88INOnTql3bt3a8WKFapevXq6dYeHh+vatWsaPny4jh49qh9++EFDhw5VpUqV1KhRo+zaXQ64xgIAAAD4P7169VK1atUUGxurN954Q9euXVOxYsVUvXp1LVu2TE8//XSa81WtWlX9+/fXokWL9Omnn6pixYqaPHmyLly4oF69eumVV17R+vXrNWfOHM2ePVuLFy+WxWJRyZIl1bVrV3Xp0kU5cuTQwoUL9f7776tbt266du2aihYtqnr16qlfv37p1lyqVCnFxsZq4sSJatmypby9vRUSEqIhQ4YoR46/7jyCh5HZS9+z2K5duxQYGChvb29Xl4JHnMVi0Z49e1S5cmV5enq6uhyAPgm3Q5+EO6E/ug+GQgEAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATPNydQGSdOfOHUnSjRs3bP8HXMVisUiSrl+/Lk9PTxdXA9An4X7ok3An9Me/hre3t3LkuP85CQ/DMIy/qJ50Xb9+XQcPHnR1GQAAAADSUL58eeXNm/e+bdwiWNy5c0c3b950dRkAAAAA0vDQnLEAAAAA8HDj4m0AAAAAphEsAAAAAJjm0mBx8+ZNvffee2rRooXq16+vLl266Ntvv3VlSXjE/f777+rZs6eCg4N17NgxV5cD6OLFixo7dqyaN2+uevXqqV27dlqzZo2ry8Ij6tixYxo4cKD+9a9/6bnnntMrr7yi5cuXu7osQJKUlJSkunXravTo0a4u5ZHl0mAxceJE7d69W9OmTdPatWsVGhqq/v376+jRo64sC4+oTZs2qUuXLipRooSrSwFs+vfvr+PHjysmJkabNm1S69atNWLECO3bt8/VpeERc+vWLfXo0UO+vr5atmyZNm7cqPbt22vcuHHatm2bq8vDI85isWj06NHy8nKLJyk8slwWLC5fvqyvv/5a3bp1U9myZZU7d261adNGZcuW1ZIlS1xVFh5hly5d0rx589S8eXNXlwJIkq5evaoyZcpo4MCB8vPzk5eXl9q2bav8+fMrMTHR1eXhEXPjxg29/vrr6tu3rwoUKCAvLy+1aNFC+fPn108//eTq8vCIW7hwoSwWi+rVq+fqUh5pLot1Bw8eVEpKiipWrGg3PTAwUPv373dRVXiUtWrVSpJ07tw51xYC/B8fHx+NGDHCbtqFCxd07do1FS9e3EVV4VFVsGBB23FSuht8ly9frjt37igkJMR1heGR99NPPykuLk4LFixQXFycq8t5pLksWFy4cEGSVKBAAbvpBQsW1Pnz511REgC4tdu3b2v48OF68skn1aRJE1eXg0dYkyZNdP78eZUpU0bTpk3Tk08+6eqS8IhKTk7WqFGj9Oqrr9IP3QB3hQKAh8C5c+fUs2dPXbx4UVFRUYwjhkutXbtWmzZtUps2bdSnTx+G5sFlZs+eLW9vb4WFhbm6FMiFweKxxx6TdHdc+70uXrxoew0AIP3yyy/q3LmzihUrpg8//JBjJNxC/vz51a5dO1WrVk2LFy92dTl4BO3Zs0dLlizR6NGj5enp6epyIBcOhSpfvrxy5cqlffv22d2FZ+/evapRo4arygIAt3L06FG9/vrrevnll9W9e3dXl4NH2LZt2zRhwgR9+umnyp8/v216SkqKvL29XVgZHlVffPGFkpOT9dprr9mm3bhxQ5K0detWbdiwwVWlPbJcFix8fHzUokULRUdHy9/fX35+flqyZIlOnjypl19+2VVlAYDbsFgsGjlypJo2bUqogMsFBQXJYrFowoQJGjBggPLnz68NGzbou+++05gxY1xdHh5B/fr1U8+ePe2mTZ061fYa/noehmEYrlr57du3NX36dK1du1ZXr16Vv7+/+vTpo6pVq7qqJDzCWrdurdOnT+vOnTtKSUlRzpw55eHhoSpVqmjmzJmuLg+PoD179ig8PNzWF+9Fv4QrHDt2TFFRUUpMTJRhGHr88cf1n//8Ry1btnR1aYAk2R6Ox0PyXMOlwQIAAADA3wN3hQIAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrDAI+vatWtq2bKlwsPDZRiGfvvtNwUEBGjZsmV27c6ePaupU6eqefPmCg4OVmBgoOrWras33nhDP/zwg13bqKgoBQQE6MiRI2mu07qOSZMmpfn66dOnVb58eQUEBOjgwYNptrGuI/W/6tWrq3v37tq1a1cm9kbmWLcnKioq29YxZMgQNWzYUJJ04sQJVatWTVOnTs3wcmbOnKkqVaro2LFjWVzh30tAQICGDBni6jJgUsOGDfXyyy9neL6wsDDb3xseDtb3hN9++y3b1rFs2TIFBATom2++cXoeM8drPLwIFnhkjR49WufPn9f7778vDw+PNNucO3dObdq00bJly9SmTRvNmTNH8+fPV48ePXTo0CF16tRJe/fuzbKali5dKk9PT+XJk0fx8fH3bTt9+nQtXbpUS5cu1Weffabhw4fr9OnTCgsL07fffptlNbmTUqVK6d1339WcOXO0efNmp+fbvn27oqKiNGbMGJUpUybb6vs7WLp0qXr16uXqMjJt/vz5CgsLc3UZyIDz58+rXLly2frBeP/+/QoICMi25bvSyy+/rKVLl6pYsWK2aaGhoQ5fkv3VMnu8xsONYIFHUmJiolasWKG33npLhQsXTrfdkiVLdPbsWU2fPl1du3ZVcHCwatSoobCwMH3yySeyWCyKi4vLkpoMw9CyZctUp04d1atXT19++aVu376dbvunn35aFStWVMWKFVW5cmW1bNlScXFxyp8/v6ZPn54lNbmjZs2aqUaNGho9erRu3LjxwPYWi0XvvvuuqlWrphYtWvwFFT7cKlasqMcff9zVZWTa999/7+oSkEG7du2SYRjZuo7ExMRsXb4rFS9eXBUrVlSuXLkkSRcvXtQvv/zi4qruyujxGg8/ggVMCQsLU8uWLXXw4EG98sorqlSpkho2bKgVK1YoOTlZ48ePV+3atfXss8+qX79+unz5st38W7duVYcOHVS5cmVVqVJF7dq1S/NUa3x8vF566SUFBQXp2WefVfv27ZWQkJBmLb/++qtee+01Va1aVXXq1NGwYcN09epVu7ZRUVEqWbKkWrZsed/tO336tKS737ykVrx4cX377beaPHmyU/vqQb799ludPHlSTZs21YsvvqiLFy9q/fr1GVpGwYIFVblyZe3bty/NN+qkpCQFBATogw8+cHht69atCggI0NKlSyVJFy5c0NixY/Xcc8+pQoUKatCggYYOHao//vgj3fWnN9TryJEjDkOmDMNQXFycmjdvrgoVKqhGjRrq06ePfv311wduZ69evXTq1KkHntWRpC+//FJHjx7V66+/bjf9QduXkX11+/ZtTZ8+XY0bN1aFChVUu3ZtDR06VGfPnnXYNwsWLNDgwYNVpUoVbdq0yalarE6cOKEePXqoSpUqqlGjhkaNGqUTJ05k6b5NPRSqYcOGeuONN5SQkKAWLVooKChIzZo10/bt23X16lUNHjxY1atXV61atTR69Gi7MBwQEKCRI0dq1apVeuGFF1ShQgU1bNhQixYtslvnzZs3NW3aNDVs2FAVKlRQ3bp11adPHyUlJdm1s1gsiomJ0QsvvKCgoCA1adJE06dPt60zICBAGzdu1HfffffAIXoWi0Xz5s1T06ZNVaFCBQUHB+u1115zGN4YEBCgcePGafPmzXrppZdsx7jo6OgH7ksz+066+8VGy5YtFRQUpCpVqqhDhw7aunWrw74bPXq0atSoocqVK6tDhw46cOBAmvU4e7x1RmJiorp06aKqVauqYsWKevHFF7Vw4UK7405YWJjq1KnjMO/LL79sG241ZMgQ2xmyRo0a2aaHhYXp+eef16FDh9SuXTtVqlRJNWrUUEREhG7evGlbVnpDvurUqWM7cxUWFqYJEyZIuvv7vN8ZLbPvac68V1ksFkVGRqpevXoKCgpS+/bt9eOPPyo8PNxuGNqQIUMUHBysP/74Q3369FH16tVVo0YN9e7d2+7YcO9QqGXLlqlGjRoyDENDhw61TU9vmO6kSZMchlElJCSoVatWqlixop577jlFRkbKYrE47KurV69q7NixatCggSpUqKD69etr3LhxunLlil27jByv8fAjWMC0q1evatSoUerUqZOioqLk7e2tYcOGaciQIbpz546mTp2qsLAwrVq1yu6b9M2bN6tbt27Kly+foqKiFBkZKV9fX/Xo0UNbtmyxtYuPj9ewYcNUpUoVzZ8/X5MmTZLFYlG3bt30008/OdTy1ltvqXHjxpozZ45CQ0MVHx+vyMhIW5uTJ09qx44dat68uXLmzHnfbfP395ckjRgxQn/++afD6/nz58/MLkvTkiVLlDdvXj3//PMKCQlRwYIFM3Ug9vT0TPfbvyeeeEKBgYFpBpbVq1crV65cev755yVJvXv31hdffKF+/fopLi5OPXv21OrVq9W7d+8s+XZx0qRJGj9+vJ577jnNnz9fo0aN0uHDh9W+fXudOXPmvvNWr15dJUuW1FdfffXA9cTHx6to0aKqW7eu3fQHbV9G9tWgQYMUHR2tl156SQsWLFD//v21fft2dejQQdevX7eb96uvvpKHh4diYmJUqVIlp2qRpOTkZIWHh2v37t0aPHiwpk6dqpSUFA0aNChL921afv/9d0VGRqpv376aNGmSLl++rAEDBmjgwIEqVaqUoqKi1KRJE33yySdavHix3by7du1STEyM+vXrp5iYGJUuXVpjx47V6tWrbW1GjRql6Ohovfrqq4qLi9PAgQO1e/duhYeH233LOWHCBE2ePFkvvviioqOj1aFDB82bN0+jRo2SdHcYV9GiRRUYGKilS5fe9xqDd999V1OnTtXzzz+v6OhojR8/XleuXFHHjh0djiv79u3TtGnT9Prrr2vOnDkqW7asJk2apLVr12bbvouOjtY777yjSpUqadasWZoyZYry5s2r7t2724WLiIgIffrpp2rfvr3mzJmjFi1aaMiQIbp27ZpdHc4eb51hDRUWi0UTJ07UvHnzVLduXU2YMMHuWOuMXr162X5Ps2fP1uzZs22vXbhwQYMHD1br1q0VExOjFi1aaPHixXr//fcztI4xY8YoJCRE0t0+MmbMmPu2z+x7mrPvVbNmzdLs2bMVEhKiOXPmqHnz5urTp49+//13h1osFot69+6toKAgzZw5U6+99prWrl2rESNGpFl7SEiIbft69erlMETqQY4dO6YePXrIMAxNmjRJ7777rk6ePKn58+c71BUeHq4vvvhCXbt21YIFCxQeHq7PP/9c3bp10507d2xtM3K8xt+AAZjQsWNHw9/f39i+fbtt2pIlSwx/f3+jc+fOdm3r169vtGrVyvbzCy+8YISGhhq3b9+2TUtOTjaaNm1qtGzZ0jZt7ty5Rq9eveyWdfDgQcPf39+YNm2aQy1r1661Tbtz545Rp04do1mzZrZpn332meHv7298++23dss8ceKE4e/vb8THx9um3bx502jXrp3h7+9vBAYGGl26dDGioqKMHTt2GMnJyQ77Y/r06Ya/v79x+PDhNPeXdR0ffPCB3fTz588bgYGBxpAhQ2zT3n33XaNcuXLGqVOnnF7HrVu3jLp16xqtW7dOc/2GYRgxMTGGv7+/cejQIdu05ORko3r16kbv3r0NwzCMy5cvG7169TI++ugju3nHjRtn+Pv7G8ePH7fbnunTp993+w4fPmzX7vTp08YzzzxjjBo1yq7d8ePHjcDAQGPcuHG2aYMHDzZCQkIctmPYsGFG+fLljUuXLqW7rdeuXTMCAwONAQMG2E13dvuc2Vd79+41/P39jXnz5tkt6/vvvzf8/f2NhQsX2u2bevXqGSkpKRmuZd26dYa/v7+xaNEiu3Zdu3bN9L5Ni7+/vzF48GDbzyEhIUZAQIDx66+/2qZFRkYa/v7+xrBhw2zTbty4YQQGBhpvvvmm3bLKly9v/Pbbb7ZpV65cMYKCgoywsDDDMO7+jQ4YMMDub9kwDGPhwoWGv7+/kZCQYBiGYZw9e9YoV66c8f7779u1mzBhglG7dm3jwoULtno7dux43208efKkERAQYIwYMcJu+h9//GEEBgYaAwcOtNuGihUrGqdPn7ZNs/bn0aNH33c9md13169fN6pUqWJ07drVbnk3b940ateubbRv394wDMO4dOmS8cwzzxhvvfWWXbtNmzYZ/v7+Rtu2bW3TnD3eduzYMc2/t3t16tTJqF69unH16lW76T179jSCgoJs0zt27GjUrl3bYf62bdvarcN6TDtx4oRdHf7+/sbnn39uN+8rr7xiBAUFGbdu3TIM4+4+vnc7rWrXrm3XDwYPHmz4+/vfd7vuXW9m3tOcea+yWCxG9erVjZdeesmu3VdffWX4+/vb7RdrzQsWLLBr27ZtW6NSpUq2n1Pvvx07dji8l6X3vvHBBx/Yzfvee++l2a5169aGv7+/sWXLFsMwDGPlypWGv7+/sXLlSrt2n3/+ueHv72+sW7fObrozx2v8PXDGAqZ5eXmpRo0atp9LlCghSapdu7ZdOz8/P9tp41OnTunIkSNq0qSJ3VkDLy8vNWjQQAcPHrSd7u7evbvDkIbSpUvblnMvT09P2zdTkuTh4aHHH39cly5dsk378ccfJUmBgYEP3LbcuXMrLi5OY8eOVeXKlfXdd98pKipKnTp1Up06dTRjxgylpKQ4zNesWbM079zUqFGjNNfzxRdfKDk5WW3atLFNe+mll3Tnzh0tX778gXVaLBYdPXpUAwcO1NmzZ9W9e/d02zZr1kweHh5at26dbdqOHTt08eJFhYaGSrp7JiYqKkodOnSwm/eJJ56Q9P+HiGVWQkKCUlJS1KxZM7vppUqVUkBAgPbs2fPAZQQGBspisejQoUPptvnll1+UnJzs8Lt2dvuc2VfWb49Tb0twcLAKFSrksC01a9aUp6dnhmuxfuOZemjJvX1Gypp9m9o//vEPlS1b1vaz9W/83lq8vb1VqFAhh6Eh5cqVU8mSJW0/+/j4qFKlSrYhGR4eHvrggw/Up08fu/lSb/+OHTt0584dhzNPQ4YM0fbt21WwYEGnt+e7776TYRj617/+ZTe9SJEiqlChgsN4/KCgIBUvXtz2s3VoZOptTUtm9t3+/ft17do1h/py586tmjVrau/evUpOTtaPP/6olJQUh2NtnTp17I6rGTnePkhycrJ27dql2rVrK1++fHavNWjQQDdv3rQdY83y8PBwOGbWqVNHN2/e1IkTJ7JkHWnJzHua5Nx71ZkzZ3Tx4kWHfvz888877E+r1PugVKlSunHjxn2vwcusH374QcWKFdNTTz1lN/3e91VJ2rZtm7y8vNSkSROHWnPkyOFwnHHmeI2/By9XF4CHn6+vr90HJS+vu93qscces2uXM2dO27AO63CMqKiodMdBnz17VqVLl9aFCxc0b948bdiwQadPn9atW7dsbYxUQ3IKFixoW39a65Xunl738vJSgQIFnNo+Ly8vtW3bVm3bttX169e1Z88ebd++XV988YWioqJ06tQpjRs3zm6emTNn2n2Yuneb0vrQHx8frxIlSujJJ5/U+fPnJd19MytbtqyWL1/ucH2A5PhBVrp73cfEiRNtQ3TS4ufnp2rVqmnNmjW2sc2rV69WgQIFVL9+fVu7xMRELViwQHv27NH58+ftTm3f+//MsF57kN5YZz8/vwcuo1ChQpJk219psb5mbXsvZ7bPmX1l7cvp3aIz9dCjtG4W4Ewt1m0pWrSo3bz3fmiVsmbfppb6b9n6N5Z6W1L/rUl3P1intbzExEQZhiEPDw8dOnRIMTEx2rFjh86fP28X1q3bb92u1LVkhvV3cm9YsCpatKj2799vN61IkSJ2P1svknXm7yAz++5B9SUnJ+vChQs6d+6cbVrqZd3b5zNyvH2QCxcuKDk5Od3arMvKCgUKFJCPj4/dNOv+vHDhQpasIy2ZeU+z1vSg9yrrkNrUvzMvLy+VKlXK4fqEtNpaw2Hqv7WscO7cOYf1SXIYTnXmzBmlpKSk+wVd6uOeM8dr/D0QLGBaerdqTW/6vV599dV0L6AuVqyYDMNQ165d9fPPP6t79+6qVauW8ufPr+TkZLVt2zZT67xy5YrDm5Wz8ubNq9q1a6t27dp688031a5dOy1btkwjRoyQt7e3rV3ZsmUdvvGR0r4mY8+ePfr5558lSbVq1Upzvd99952qV69uN+3e8OLh4SEfHx+VLFnSqX3QrFkzRUREKCkpSSVLltS6devUpEkT2wemffv2qXPnznr88cc1cOBAlS1bVrly5dLq1as1Z86cBy7fWZMnT05zP+XI8eCTqdZgmNYbsZX1tdT7PSPb96B9ZbVo0aI0f7+5c+e2+zl18HW2FuuHlNT7Jr3ft5l9m5qZv/G01mcYhnLkyCEPDw+dOnVK7du3V548edS7d28FBATI29tbu3fvVkREhMNykpOTM1x/Ruq21uZs+8yu637LfFB90t39cb8Plmm99qDjrTOcre1+nP1AnNa6rPM+6Hdi5kN3Zn5nzr5Xpfd3nNn1mpV6P6W339IK0Xny5NEnn3ySZvvU77HOHK/x90CwgEtYTy1bLBaVL18+3XY//fSTDhw4oI4dO+qtt96yTT9+/Him1+3j4+Nwl6i03L59W7t27VK+fPkUFBTk8HrevHn13HPP6dChQ/rzzz/TPEPhjKVLlypHjhyaPn26w6nwW7duqVevXoqPj3cIFumFF2e88MILGjdunNatW6dnnnnGbmiPJK1cuVIpKSmaPHmyKlSoYJu+Zs2a+y7X+maZenhY6m8wrd+ae3t73/f3fz/WIQj3u4De+uaW+s0sI9v3oH1l7cv58+fP1LY4W4uvr6+ku9945s2b1zY99Z2TsmLfZqW07iL2559/2oYurV+/XteuXdOECRPszrSlPmtg3a5Tp07ZfUuanJysGzduKG/evA6hLT3Wb9tPnz7t8GyDM2fOpPlt/F/p3vpSO3PmjHLnzq2CBQvaznqkvrHErVu3dP78edvZImePt84oVKiQcufOnW5t0v8PKR4eHmkOFf3jjz+cCrhXrlzR7du37UK89Rtv67antQ7rGZ2/0s8//+zUe5W131vPNlnduXNHv/32m9Nn0jPKGk5S76vUf5+FCxdO83ebethxiRIldOPGDZUsWdKpmp05XuPvgWss4BLFixfXU089pTVr1jiME/3www/18ccfS5LtFneph28sXLjQ7vWMKFSokFJSUpwaH92/f/8077Ai3T1AJyYmqmDBgpn+IHL9+nWtWrVKNWvWVOPGjW1nQ6z/QkJCVL9+fa1Zs8apMOSswoULq1atWtqyZYvWrVun4sWL2wUX65uP9QOJdPdN3vrApfSGgFjfYFLf3WTjxo12P1uvM1ixYoXddIvFotGjRzv1gD/rB4f7PYfE+lrqDxkZ2b4H7SvrWPnU23L16lUNGzZM+/btu+92OFuL9QPhzp077eZPfQ1OVuzbrLR//3674Q9Xr17V3r17bdtj/Ru+d/uTk5MdjgGVK1dWjhw57K53ke7eSah69ep2H64fdFyw7qPUd/w6ffq0Dhw4kO6Zw79KxYoVVaBAAYf6rl+/roSEBD377LPy8vLSM888oxw5cmjbtm127TZv3my3D5w93jrDy8tL1atXV0JCgsNxccOGDSpQoIAqVqwo6W4Yvnz5sl2wP3DggMOHVOuH3tTHFYvF4nB73e3bt8vHx8d2nYuvr69Onz5tN++WLVsclmVdR2beM5zh7HtV6dKllTdvXn333Xd27datW5dl3+anta3WLybuPTbfvHnT4XgQGBhouybHyjAM262xrazXm6Q+zvz+++965513HL7wcOZ4jb8HggVcpn///vrjjz/06quvauvWrdqxY4fGjh2rDz74wHaLySeffFJFihTRJ598oo0bNyohIUEDBw7U7du3VaxYMe3evVvff/99hsb8W7/tfNAFhrly5dLIkSN1/PhxtW3bVh9//LESExOVmJiozz//XJ06ddKePXs0dOhQp78pTW3lypW6du2awwW492rTpo1u3LihVatWZWod6WnWrJn+97//acOGDWrevLndN4jWCxfHjx+vxMRErVq1Sq+88opat24tSfr666919OhRh2X6+PgoODhYGzdu1OLFi/Xdd99p2rRpDrfvLFasmDp37qw1a9ZoxIgRSkxM1ObNm9W9e3ctXbrUYfhQWg4cOCBPT0+VK1cu3Tb//Oc/lTNnTof7+md0++63r4KCgvT8889rwYIFmjJlinbt2qW1a9fq1Vdf1dq1ax/4bZ6ztYSEhOixxx7TlClTtHz5ciUkJGjEiBEOHxSzYt9mpccff1zh4eFat26ddu7cqT59+ujWrVu2a0CCg4Pl4eGhqVOnaufOnVq/fr06dOhgu2Zl48aNOnTokEqUKKF27drp888/17Rp05SYmKhFixYpJiZGrVu3toX7YsWK6eDBg/riiy/SfSha8eLFFRYWpqVLl2ratGnauXOnVq1apZ49e9pu6epKuXPnVu/evbV9+3aNGTNGCQkJWr9+vV5//XVdu3bN9o144cKF9fzzz2v16tWKjIzUzp07tXjxYk2ePNlhnLwzx1tn9enTR9euXdMbb7yhTZs22erctm2bevXqZetj9evX1507dzRixAjt3LlTX375pQYPHuxw1sRaa1xcnFatWmX7QFygQAFNmzZNS5YsUWJioiZMmKDdu3erXbt2tmNu/fr19eeff2r8+PH6/vvv9d///ldRUVEOD3m0rmPu3LkZfj6QM5x9r/L09FSrVq2UmJioiRMnaseOHfr44481Y8aMTJ+BTs26rStXrtTatWt1+vRp1atXT56enpo6daq2bNmiLVu2qEePHrabJFi1bdtWXl5e6tu3r9atW6ctW7bojTfecFhHkyZNVKlSJb333nuaP3++du/erRUrVujVV1/Vtm3bbEHGypnjNf4eGAoFl2nUqJHmzZunOXPmqE+fPkpJSdFTTz2liRMnqlWrVpLuDueYPn26xo0bp379+qlQoUJq2bKlevfurc8++0yTJ09Wv379HL4Rvx/rN8wJCQkP/GayadOmKlGihGJjYxUdHW07bVy0aFFVrVpVQ4YMSXOYlLPi4+NVoEABNW7cON029evXV5EiRRQfH3/f+/JnVJMmTTR69GidOXPGbmiPJDVu3Fh9+vTRf//7X61fv15PP/20Bg0apNq1a2vPnj1avny5cufOrc6dOzssd9y4cYqIiNCUKVPk5eWlhg0bauLEiWrQoIFdu0GDBsnPz09LlizR8uXLlTNnTlWtWlVxcXGqWrXqA+tPSEiwfbObnnz58qlKlSoOD6hydvuGDx/+wH0l3X1uxJw5c/Tll19q/vz5ypMnj2rWrKnx48c7vHGnlpFaoqOj9e6772rkyJEqWLCgWrVqpbCwMIWGhtqNwza7b7NSuXLl1LhxY0VGRiopKUnFixe3PQxQkipUqKCIiAjNmzdP3bp1U+nSpRUeHq5WrVopKSlJa9eulaenp2bMmKHhw4erWLFiio+PV3R0tAoVKqRu3brZBYE33nhDw4YN0/Dhw9WuXTsFBwenWdfgwYNVtGhRLVmyRNHR0cqbN6+qV6+uyZMnu8WTxzt16qR8+fIpNjZWS5YsUa5cuVS5cmV99NFHdsecsWPHKk+ePFq8eLEWLFigwMBATZ061eE5B84cb50VFBSkuLg4TZs2TW+//bZSUlL09NNPOyyrVatW+vXXX7Vy5Upt2rRJ5cqV07vvvqt58+bZnTFu1qyZVqxYoU8//VRr1qyx3Q0rV65cmjhxosaNG6d9+/YpT5486ty5s90dxMLDw3X27Fl9/fXXio+PV6VKlTR16lT169fPrub//Oc/2rJli2bOnKmAgACHO26ZlZH3qsGDByslJUXx8fH67LPPVK1aNU2fPl2DBw92+u5c91O2bFm98sor+vzzz7V//37NmzdPVatW1fjx4zVnzhz17t1bfn5+6tGjh65cuWIXwMuVK6eoqCjbPixUqJBat26tNm3a6M0337S18/LyUkxMjKZPn664uDhNnjxZ+fPnV0hIiHr37u1wlzZnjtf4m/jr7mwLuI+wsDAjJCTE7lkUaT3HAq6X1nMsrM+IiIuLe+D8y5cvd7gv/d+J9Tka8+fPd3UpDvz9/Y2+ffu6ugw8hNJ7Bsbf2QsvvGC8+OKLri4jy2XkeI2HH0Oh8Ejq06ePTp486TA+FA+HGTNmyM/PT//+978f2DY0NFRlypSxe6Lvw+jy5csaOnSoPvvsM7vp33zzjSQxxAB4SMTFxWnAgAF2d2A6fvy4jh075hY3XMhqGTle4+HHUCg8koKDg9WiRQtFRkaqQYMGXFD2EFm9erUSEhI0Z84c5cmT54HtPT09NXLkSL322mtauXKlmjdv/hdUmfUKFCigEydO6Ouvv1ZKSooCAgL0ww8/KDo6WhUqVLB7oBcA95U3b159+eWXMgxDL7/8sq5cuaLp06crR44caQ4vfZhl9HiNhx/BAo+s0aNHq3379ho8eLDmzZvn6nLghBMnTuidd95Rz549HZ4Eez916tRR7969NWLECAUGBqpMmTLZV2Q2mjFjhiIjIxUdHa1z586pYMGCCg0NVf/+/TP1fAoAf71///vf8vDwUFxcnHr06CEPDw9VqFBB8+fPT/eBcw+jzB6v8XDzMIxseHQjAAAAgEcKX3EBAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADDt/wFmBvEDawuPuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCdAP5Q-13_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}